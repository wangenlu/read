# 03 数据

- 数据吞吐
- JSON文档(JSON document)
- Elasticsearch是一个分布式的文档(document)存储引擎
- 文档元数据
- _index 索引(index)类似于关系型数据库里的“数据库”——它是我们存储和索引关联数据的地方
- _type 我们使用相同类型(type)的文档表示相同的“事物”，因为他们的数 据结构也是相同的
- 映射
- _id id仅仅是一个字符串，它与 _index 和 _type 组合时，就可以在Elasticsearch中唯一标识一个 文档。
- 使用自己的ID
- 自增ID URL-safe, Base64-encoded string universally unique identifiers, 或者叫 UUIDs
- 检索文档
- 检索文档的一部分
- 检查文档是否存在
- 更新整个文档
- 文档在Elasticsearch中是不可变的——我们不能修改他们 
-  index API 重建索引(reindex) 或者替换掉它
- 局部更新
- 悲观并发控制（Pessimistic concurrency control）
- 乐观并发控制（Optimistic concurrency control）
- version_type=external
- update API update API处理相同的检索-修改-重建索引流程
- 使用Groovy脚本
- upsert 更新插入
- 检索多个文档 _mget

## 文档

通常，我们可以认为对象(object)和文档(document)是等价相通的。不过，他们还是有所差 别：对象(Object)是一个JSON结构体——类似于哈希、hashmap、字典或者关联数组；对象 (Object)中还可能包含其他对象(Object)。 在Elasticsearch中，文档(document)这个术语有着 特殊含义。它特指最顶层结构或者根对象(root object)序列化成的JSON数据（以唯一ID标识 并存储于Elasticsearch中）。

一个文档不只有数据。它还包含了元数据(metadata)——关于文档的信息。三个必须的元数 据节点是：

|节点| 说明|
|----|-----|
|_index | 文档存储的地方 
|_type  |文档代表的对象的类 
|_id    |文档的唯一标识

在Elasticsearch中，每一个字段的数据都是默认被索引的。也就是说，每个字段专门有一个反向索引用于快速检索。
而且，与其它数据库不同，它可以在同一个查询中利用所有的这些 反向索引，以惊人的速度返回结果。

- _index
事实上，我们的数据被存储和索引在分片(shards)中，索引只是一个把一个或多个分片 分组在一起的逻辑空间。

- _type
每个类型(type)都有自己的映射(mapping)或者结构定义。

- _id
当创建一个文档，你可以自定义 _id ，也可以让Elasticsearch帮你自动生成。


## 索引

```json
PUT /{index}/{type}/{id}
{
    "field": "value",
     ...
}
```

## 检索文档

想要从Elasticsearch中获取文档，我们使用同样的 _index 、 _type 、 _id ，但是HTTP方法 改为 GET ：

- 检索文档
- 检索文档的一部分
- 只想得到 _source 字段而不要其他的元数据

```
GET /website/blog/123?pretty
GET /website/blog/123?_source=title,text
GET /website/blog/123/_source 
```

## 更新文档

- 局部更新
我们将会在《局部更新》中探讨 update API。这个API 似乎 允许你修改文档 的局部，但事实上Elasticsearch遵循与之前所说完全相同的过程，这个过程如下：
 1. 从旧文档中检索JSON 
 2. 修改它 
 3. 删除旧文档 
 4. 索引新文档

唯一的不同是 update API完成这一过程只需要一个客户端请求既可，不再需 要 get 和 index 请求了

## 文档局部更新

```json
POST /website/blog/1/_update 
{
    "doc": {
        "tags": [
            "testing"
        ],
        "views": 0
    }
}
```

## 使用脚本

脚本能够使用 update API改变 _source 字段的内容，它在脚本内部以 ctx._source 表示。例 如，我们可以使用脚本增加博客的 views 数量：
```json
POST /website/blog/1/_update
{
    "script": "ctx._source.views+=1"
}
```

## 批量

整个批量请求需要被加载到接受我们请求节点的内存里，所以请求越大，给其它请求可用的 内存就越小。有一个最佳的 bulk 请求大小。超过这个大小，性能不再提升而且可能降低。 

最佳大小，当然并不是一个固定的数字。它完全取决于你的硬件、你文档的大小和复杂度以 及索引和搜索的负载。幸运的是，这个最佳点(sweetspot)还是容易找到的： 
试着批量索引标准的文档，随着大小的增长，当性能开始降低，说明你每个批次的大小太大 了。开始的数量可以在1000~5000个文档之间，如果你的文档非常大，可以使用较小的批 次。
通常着眼于你请求批次的物理大小是非常有用的。一千个1kB的文档和一千个1MB的文档大不 相同。一个好的批次最好保持在5-15MB大小间。
