# NACOS 阿里云


> 关键字

- AP 系统
- 配置推送（3秒以内，大规模集群）
- 服务注册、服务发现与配置管理（配置中心）
- NACOS设计，架构，实现
- 服务发下与管理
- 动态DNS服务
- 动态配置服务
- Nacos 2.0 长链接协议
- 配置(Configuration)
- 配置管理 (Configuration Management)
- 配置服务 (Configuration Service)
- 配置项（Configuration Item）
- 配置集（Configuration Set）
- 命名空间（Namespace）用于进行租户粒度的配置隔离。 例如开发测试环境和生产环境的资源 （如数据库配置、限流阈值、降级开关）隔离等
- 配置组（Group）
- 配置 ID（Data ID） Data ID 通常用于划分系统的配 置集
- 配置快照（Configuration Snapshot）
- Nacos ⼀致性协议
- 共识算法
- 为什么 Nacos 选择了 Raft 以及 Distro
- AP、CP 协议下沉到
- ⼀致性协议抽象
- Response getData(ReadRequest request) throws Exception;
- Response write(WriteRequest request) throws Exception;
- —数据存储抽象
- KvStorage
- Nacos 长链接
- 低成本快速感知

## Nacos 优势

- 易⽤：简单的数据模型，标准的 restfulAPI，易用的控制台，丰富的使用文档。 
- 稳定：99.9% 高可用，脱胎于历经阿里巴巴 10 年生产验证的内部产品，支持具有数百万服务的大 规模场景，具备企业级 SLA 的开源产品。 
- 实时：数据变更毫秒级推送生效；1w 级，SLA 承诺 1w 实例上下线 1s，99.9% 推送完成；10w 级，SLA 承诺 1w 实例上下线 3s，99.9% 推送完成；100w 级别，SLA 承诺 1w 实例上下线 9s 99.9% 推送完成。
- 规模：十万级服务/配置，百万级连接，具备强大扩展性。

## 设计原则

-  极简原则，简单才好用，简单才稳定，简单才易协作。
-  架构⼀致性，⼀套架构要能适应开源、内部、商业化（公有云及专有云）3 个场景。
-  扩展性，以开源为内核，商业化做基础，充分扩展，方便用户扩展。
-  模块化，将通用部分抽象下沉，提升代码复用和健壮性。
-  长期主义，不是要⼀个能支撑未来 3 年的架构，而是要能够支撑 10 年的架构。
-  开放性，设计和讨论保持社区互动和透明，方便大家协作。


## 业务层 

-  服务管理：实现服务 CRUD，域名 CRUD，服务健康状态检查，服务权重管理等功能。 
-  配置管理：实现配置管 CRUD，版本管理，灰度管理，监听管理，推送轨迹，聚合数据等功能。
-  元数据管理：提供元数据 CURD 和打标能力，为实现上层流量和服务灰度非常关键。

## 内核层 

-  插件机制：实现三个模块可分可合能力，实现扩展点 SPI 机制，用于扩展自己公司定制。 
-  事件机制：实现异步化事件通知，SDK 数据变化异步通知等逻辑，是 Nacos 高性能的关键部分。 
-  日志模块：管理日志分类，日志级别，日志可移植性（尤其避免冲突），日志格式，异常码+帮 助文档。 
-  回调机制：SDK 通知数据，通过统⼀的模式回调用户处理。接口和数据结构需要具备可扩展性。 
-  寻址模式：解决 Server IP 直连，域名访问，Nameserver 寻址、广播等多种寻址模式，需要可 扩展。 
-  推送通道：解决 Server 与存储、Server 间、Server 与 SDK 间高效通信问题。 
-  容量管理：管理每个租户，分组下的容量，防止存储被写爆，影响服务可用性。 
-  流量管理：按照租户，分组等多个维度对请求频率，长链接个数，报文大小，请求流控进行控制。 
-  缓存机制：容灾目录，本地缓存，Server 缓存机制，是 Nacos 高可用的关键。 
-  启动模式：按照单机模式，配置模式，服务模式，DNS 模式模式，启动不同的模块。 
-  ⼀致性协议：解决不同数据，不同⼀致性要求情况下，不同⼀致性要求，是 Nacos 做到 AP 协 议的关键。 
-  存储模块：解决数据持久化、非持久化存储，解决数据分片问题。

## Nacos 配置管理的基础模型

1. Nacos 提供可视化的控制台，可以对配置进行发布、更新、删除、灰度、版本管理等功能。
2. SDK 可以提供发布配置、更新配置、监听配置等功能。
3. SDK 通过 GRPC 长连接监听配置变更，Server 端对比 Client 端配置的 MD5 和本地 MD5 是否相等，不相等推送配置变更。
4. SDK 会保存配置的快照，当服务端出现问题的时候从本地获取。

## Nacos ⼀致性协议

> 为什么 Nacos 需要⼀致性协议

 Nacos 在开源支持就定下了⼀个目标，尽可能的减少用户部署以及运维成本，做到用户只需要⼀个 程序包，就可以快速以单机模式启动 Nacos 或者以集群模式启动 Nacos。而 Nacos 是⼀个需要 存储数据的⼀个组件，因此，为了实现这个目标，就需要在 Nacos 内部实现数据存储。单机下其 实问题不大，简单的内嵌关系型数据库即可；但是集群模式下，就需要考虑如何保障各个节点之间 的数据⼀致性以及数据同步，而要解决这个问题，就不得不引入共识算法，通过算法来保障各个节 点之间的数据的⼀致性。

 ## 为什么 Nacos 选择了 Raft 以及 Distro

 为什么 Nacos 会在单个集群中同时运行 CP 协议以及 AP 协议呢？这其实要从 Nacos 的场景出 发的：Nacos 是⼀个集服务注册发现以及配置管理于⼀体的组件，因此对于集群下，各个节点之间 的数据⼀致性保障问题，需要拆分成两个方面 
 
 - 从服务注册发现来看

服务发现注册中心，在当前微服务体系下，是十分重要的组件，服务之间感知对方服务的当前可正 常提供服务的实例信息，必须从服务发现注册中心进行获取，因此对于服务注册发现中心组件的可 用性，提出了很高的要求，需要在任何场景下，尽最大可能保证服务注册发现能力可以对外提供服 务；同时 Nacos 的服务注册发现设计，采取了心跳可自动完成服务数据补偿的机制。如果数据丢 失的话，是可以通过该机制快速弥补数据丢失。

因此，为了满足服务发现注册中心的可用性，强⼀致性的共识算法这里就不太合适了，因为强⼀致 性共识算法能否对外提供服务是有要求的，如果当前集群可用的节点数没有过半的话，整个算法直 接“罢工”，而最终⼀致共识算法的话，更多保障服务的可用性，并且能够保证在⼀定的时间内各 个节点之间的数据能够达成⼀致。 上述的都是针对于 Nacos 服务发现注册中的非持久化服务而言（即需要客户端上报心跳进行服务实 例续约）。而对于 Nacos 服务发现注册中的持久化服务，因为所有的数据都是直接使用调用 Nacos 服务端直接创建，因此需要由 Nacos 保障数据在各个节点之间的强⼀致性，故而针对此类型的服务数据，选择了强⼀致性共识算法来保障数据的⼀致性。


- 从配置管理来看
 配置数据，是直接在 Nacos 服务端进行创建并进行管理的，必须保证大部分的节点都保存了此配 置数据才能认为配置被成功保存了，否则就会丢失配置的变更，如果出现这种情况，问题是很严重的，如果是发布重要配置变更出现了丢失变更动作的情况，那多半就要引起严重的现网故障了，因此对于配置数据的管理，是必须要求集群中大部分的节点是强⼀致的，而这里的话只能使用`强⼀致 性共识算法`。

> 核心：是否能容忍数据丢失，如果不能就是使用 `强⼀致 性共识算法`。


为什么是 Raft 和 Distro 呢 对于强⼀致性共识算法，当前工业生产中，最多使用的就是 Raft 协议，Raft 协议更容易让人理解， 并且有很多成熟的工业算法实现，比如蚂蚁金服的 JRaft、Zookeeper 的 ZAB、Consul 的 Raft、 百度的 braft、Apache Ratis；因为 Nacos 是 Java 技术栈，因此只能在 JRaft、ZAB、Apache Ratis 中选择，但是 ZAB 因为和 Zookeeper 强绑定，再加上希望可以和 Raft 算法库的支持团队 随时沟通交流，因此选择了 JRaft，选择 JRaft 也是因为 JRaft 支持多 RaftGroup，为 Nacos 后 面的多数据分片带来了可能。

而 Distro 协议是阿里巴巴自研的⼀个最终⼀致性协议，而最终⼀致性协议有很多，比如 Gossip、 Eureka 内的数据同步算法。而 Distro 算法是集 Gossip 以及 Eureka 协议的优点并加以优化而出 来的，对于原生的 Gossip，由于随机选取发送消息的节点，也就不可避免的存在消息重复发送给同 ⼀节点的情况，增加了网络的传输的压力，也给消息节点带来额外的处理负载，而 Distro 算法引入 了权威 Server 的概念，每个节点负责⼀部分数据以及将自己的数据同步给其他节点，有效的降低 了消息冗余的问题。

## Distro 协议的主要设计思想

- Nacos 每个节点是平等的都可以处理写请求，同时把新数据同步到其他节点。 
- 每个节点只负责部分数据，定时发送自己负责数据的校验值到其他节点来保持数据⼀致性。 
- 每个节点独立处理读请求，及时从本地发出响应。
